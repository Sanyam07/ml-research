name: metalearn_multiclass
experiment_type: METALEARN_REINFORCE
created_at: 2019-10-02-01-32-59
git_hash: b59eafd
parameters:
  datasets: null
  output_fp: /output
  n_trials: 1
  input_size: 128
  hidden_size: 128
  output_size: 128
  n_layers: 5
  dropout_rate: 0.3
  beta: 0.9
  entropy_coef: 0.1
  entropy_coef_anneal_to: 0.05
  entropy_coef_anneal_by: 0.9
  with_baseline: true
  single_baseline: false
  normalize_reward: true
  n_episodes: 250
  n_iter: 100
  n_eval_iter: 100
  learning_rate: 0.005
  env_sources:
  - AUTOSKLEARN_BENCHMARK
  - OPEN_ML
  - KAGGLE
  test_env_sources:
  - OPEN_ML_BENCHMARK_CC18
  target_types:
  - BINARY
  - MULTICLASS
  test_set_config:
    SKLEARN:
      test_size: 0.2
      random_state: 100
    OPEN_ML:
      test_size: 0.2
      random_state: 100
    KAGGLE:
      test_size: 0.2
      random_state: 100
  error_reward: 0
  n_samples: 10000
  per_framework_time_limit: 360
  per_framework_memory_limit: 5000
  metric_logger: floyd
  fit_verbose: 0
  controller_seed: 1000
  task_environment_seed: 100
description: |
  test metalearning capabilities
  * train agent on multiclass tasks
  * evaluation plan: test against all task held out test sets
  * evaluation plan: test against BINARY, REGRESSION tasks
  * evaluation plan: test against AUTOSKLEARN_BENCHMARK tasks

  * change default multiclass scorer to f1_macro
  * descrease entropy coefficient to reduce exploration
  * normalize rewards, maintain one baseline reward function per task env
  * increase entropy coefficient to encourage exploration
  * increase number of episodes, add entropy annealing
